#!/usr/bin/env node

const https = require("node:https");
const querystring = require("node:querystring");
const { program } = require("commander");
require("dotenv").config();

const MAX_RESULTS = 111;
const TOKEN = process.env.GH_PAT;

program.option("-v, --verbose", "print addtional information for debugging");
program.parse(process.argv);
const options = program.opts();

function debug(obj) {
  if (options.verbose) {
    process.stdout.write(JSON.stringify(obj) + "\n");
  }
}

function ghApiUrl(url, queryParams) {
  const queryString = querystring.stringify(queryParams);
  return `https://api.github.com${url}?${queryString}`;
}

function ghRequest(token, url) {
  const options = {
    headers: {
      Accept: "application/vnd.github+json",
      Authorization: `Bearer ${token}`,
      "X-GitHub-Api-Version": "2022-11-28",
      "User-Agent": "homework-gh-cli",
    },
  };

  return new Promise((resolve, reject) => {
    const req = https.get(url, options, (res) => {
      res.setEncoding("utf8");
      debug({ url, statusCode: res.statusCode });

      const { headers } = res;
      let body = "";

      res.on("data", (d) => {
        body += d;
      });

      res.on("end", () => {
        resolve({ headers, body: JSON.parse(body) });
      });

      req.on("error", (err) => {
        reject(err);
      });

      req.end();
    });
  });
}

async function paginatedRequest(token, url, queryParams) {
  let nextUrl = url;
  let data = [];

  while (nextUrl != null) {
    const { headers, body } = await ghRequest(token, nextUrl);
    data = [...data, ...body];

    // exit early, for testing
    if (data.length > MAX_RESULTS) {
      nextUrl = null;
      continue;
    }

    const linkHeader = headers.link || "";
    const links = linkHeader.split(",");
    const next = links.find((l) => l.endsWith(`rel="next"`));
    if (next != null) {
      nextUrl = next.substring(next.indexOf("<") + 1, next.lastIndexOf(">"));
    } else {
      nextUrl = null;
    }
  }

  debug({ status: "done", url, length: data.length });

  return data;
}

// https://docs.github.com/en/rest/repos/repos?apiVersion=2022-11-28#list-organization-repositories
async function getRepos(org) {
  const repos = await paginatedRequest(
    TOKEN,
    ghApiUrl(`/orgs/${org}/repos`, { per_page: 100 }),
  );
  if (!Array.isArray(repos)) {
    throw new Error("expected array, found: " + JSON.stringify(repos));
  }
  return repos;
}

// https://docs.github.com/en/rest/pulls/pulls?apiVersion=2022-11-28#list-pull-requests
async function getAllPullRequests(owner, repo) {
  const prs = await paginatedRequest(
    TOKEN,
    ghApiUrl(`/repos/${owner}/${repo}/pulls`, { per_page: 100, state: "all" }),
  );
  if (!Array.isArray(prs)) {
    throw new Error("expected array, found: " + JSON.stringify(prs));
  }

  return prs;
}

(async () => {
  try {
    const repos = await getRepos("ramda");

    // TODO iterate through all
    const pullRequests = await getAllPullRequests("ramda", repos[0].name);

    // TODO this is just example output
    pullRequests.forEach((pr) => {
      process.stdout.write(JSON.stringify(pr.title) + "\n");
    });
  } catch (e) {
    process.stderr.write(e + "\n");
  }
})();
